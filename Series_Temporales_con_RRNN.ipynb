{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Series Temporales con Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El artículo completo con la explicación detallada en el blog: http://www.aprendemachinelearning.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usaremos Keras y Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las Librerías que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:03.702007Z",
     "start_time": "2019-02-25T20:50:45.180334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('fast')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos nuestro Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:03.748521Z",
     "start_time": "2019-02-25T20:51:03.704287Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-90053daf51c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time_series.csv'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fecha'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'unidades'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\henry paz\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\henry paz\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\henry paz\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\henry paz\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1884\u001b[0m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m                 values = self._maybe_parse_dates(values, i,\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('time_series.csv',  parse_dates=[0], header=None,index_col=0, squeeze=True,names=['fecha','unidades'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:03.765627Z",
     "start_time": "2019-02-25T20:51:03.753400Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:03.777528Z",
     "start_time": "2019-02-25T20:51:03.770857Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.index.min())\n",
    "print(df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:03.794258Z",
     "start_time": "2019-02-25T20:51:03.784557Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(df['2017']))\n",
    "print(len(df['2018']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:03.859508Z",
     "start_time": "2019-02-25T20:51:03.800478Z"
    }
   },
   "outputs": [],
   "source": [
    "meses =df.resample('M').mean()\n",
    "meses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:04.096077Z",
     "start_time": "2019-02-25T20:51:03.862373Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(meses['2017'].values)\n",
    "plt.plot(meses['2018'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:04.294343Z",
     "start_time": "2019-02-25T20:51:04.099520Z"
    }
   },
   "outputs": [],
   "source": [
    "verano2017 = df['2017-06-01':'2017-09-01']\n",
    "plt.plot(verano2017.values)\n",
    "verano2018 = df['2018-06-01':'2018-09-01']\n",
    "plt.plot(verano2018.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:04.344102Z",
     "start_time": "2019-02-25T20:51:04.298243Z"
    }
   },
   "outputs": [],
   "source": [
    "PASOS=7\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# load dataset\n",
    "values = df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividimos en set de Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:04.359517Z",
     "start_time": "2019-02-25T20:51:04.349323Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_days = 315+289 - (30+PASOS)\n",
    "train = values[:n_train_days, :]\n",
    "test = values[n_train_days:, :]\n",
    "# split into input and outputs\n",
    "x_train, y_train = train[:, :-1], train[:, -1]\n",
    "x_val, y_val = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T21:40:14.487519Z",
     "start_time": "2019-02-22T21:40:14.474395Z"
    }
   },
   "source": [
    "# Creamos el Modelo de Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizaremos una Red \"normal\" Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:04.368665Z",
     "start_time": "2019-02-25T20:51:04.362320Z"
    }
   },
   "outputs": [],
   "source": [
    "def crear_modeloFF():\n",
    "    model = Sequential() \n",
    "    model.add(Dense(PASOS, input_shape=(1,PASOS),activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    model.compile(loss='mean_absolute_error',optimizer='Adam',metrics=[\"mse\"])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos nuestra máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:12.615429Z",
     "start_time": "2019-02-25T20:51:04.373597Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS=40\n",
    "\n",
    "model = crear_modeloFF()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:12.852142Z",
     "start_time": "2019-02-25T20:51:12.618559Z"
    }
   },
   "outputs": [],
   "source": [
    "results=model.predict(x_val)\n",
    "print( len(results) )\n",
    "plt.scatter(range(len(y_val)),y_val,c='g')\n",
    "plt.scatter(range(len(results)),results,c='r')\n",
    "plt.title('validate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.128405Z",
     "start_time": "2019-02-25T20:51:12.855770Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('loss')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('validate loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.311943Z",
     "start_time": "2019-02-25T20:51:13.131681Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.366609Z",
     "start_time": "2019-02-25T20:51:13.314722Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compara = pd.DataFrame(np.array([y_val, [x[0] for x in results]])).transpose()\n",
    "compara.columns = ['real', 'prediccion']\n",
    "\n",
    "inverted = scaler.inverse_transform(compara.values)\n",
    "\n",
    "compara2 = pd.DataFrame(inverted)\n",
    "compara2.columns = ['real', 'prediccion']\n",
    "compara2['diferencia'] = compara2['real'] - compara2['prediccion']\n",
    "compara2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.401663Z",
     "start_time": "2019-02-25T20:51:13.369640Z"
    }
   },
   "outputs": [],
   "source": [
    "compara2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.594591Z",
     "start_time": "2019-02-25T20:51:13.405616Z"
    }
   },
   "outputs": [],
   "source": [
    "compara2['real'].plot()\n",
    "compara2['prediccion'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la última semana de noviembre 2018, intentaremos predecir la primer semana de diciembre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:52:11.024445Z",
     "start_time": "2019-02-25T20:52:10.983681Z"
    }
   },
   "outputs": [],
   "source": [
    "ultimosDias = df['2018-11-16':'2018-11-30']\n",
    "ultimosDias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparamos los datos para Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:52:17.532182Z",
     "start_time": "2019-02-25T20:52:17.507681Z"
    }
   },
   "outputs": [],
   "source": [
    "values = ultimosDias.values\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
    "scaled = scaler.fit_transform(values)\n",
    "reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "reframed.drop(reframed.columns[[7]], axis=1, inplace=True)\n",
    "reframed.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:52:21.914334Z",
     "start_time": "2019-02-25T20:52:21.904612Z"
    }
   },
   "outputs": [],
   "source": [
    "values = reframed.values\n",
    "x_test = values[6:, :]\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "print(x_test.shape)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.693886Z",
     "start_time": "2019-02-25T20:51:13.687944Z"
    }
   },
   "outputs": [],
   "source": [
    "def agregarNuevoValor(x_test,nuevoValor):\n",
    "    for i in range(x_test.shape[2]-1):\n",
    "        x_test[0][0][i] = x_test[0][0][i+1]\n",
    "    x_test[0][0][x_test.shape[2]-1]=nuevoValor\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronóstico para la \"próxima semana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.721175Z",
     "start_time": "2019-02-25T20:51:13.697146Z"
    }
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(7):\n",
    "    parcial=model.predict(x_test)\n",
    "    results.append(parcial[0])\n",
    "    print(x_test)\n",
    "    x_test=agregarNuevoValor(x_test,parcial[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Convertimos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T21:03:35.759150Z",
     "start_time": "2019-02-25T21:03:35.746646Z"
    }
   },
   "outputs": [],
   "source": [
    "adimen = [x for x in results]    \n",
    "print(adimen)\n",
    "inverted = scaler.inverse_transform(adimen)\n",
    "inverted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos el pronóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T21:08:28.155409Z",
     "start_time": "2019-02-25T21:08:27.987373Z"
    }
   },
   "outputs": [],
   "source": [
    "prediccion1SemanaDiciembre = pd.DataFrame(inverted)\n",
    "prediccion1SemanaDiciembre.columns = ['pronostico']\n",
    "prediccion1SemanaDiciembre.plot()\n",
    "prediccion1SemanaDiciembre.to_csv('pronostico.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.944994Z",
     "start_time": "2019-02-25T20:51:13.932992Z"
    }
   },
   "outputs": [],
   "source": [
    "prediccion1SemanaDiciembre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregamos el resultado en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T20:51:13.974698Z",
     "start_time": "2019-02-25T20:51:13.948522Z"
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for fila in prediccion1SemanaDiciembre.pronostico:\n",
    "    i=i+1\n",
    "    ultimosDias.loc['2018-12-0' + str(i) + ' 00:00:00'] = fila\n",
    "    print(fila)\n",
    "ultimosDias.tail(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El artículo completo en www.aprendemachinelearning.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
